final_regressor = models/0002.model
Num weight bits = 18
learning rate = 10
initial_t = 1
power_t = 0.5
using no cache
Reading datafile = train-sets/0002.dat
num sources = 1
average    since         example     example  current  current  current
loss       last          counter      weight    label  predict features
0.271591   0.271591            1         1.0   0.5211   0.0000       15
0.147424   0.023257            2         2.0   0.5353   0.3827       15
0.087392   0.027360            4         4.0   0.5854   0.7212       15
0.065205   0.043018            8         8.0   0.5575   0.6282       15
0.052171   0.039137           16        16.0   0.5878   0.5432       15
0.028349   0.004528           32        32.0   0.6038   0.6164       15
0.015826   0.003302           64        64.0   0.5683   0.5103       15
0.010695   0.005565          128       128.0   0.5351   0.5203       15
0.007506   0.004318          256       256.0   0.5385   0.5448       15
0.005298   0.003090          512       512.0   0.5053   0.5509       15
0.003397   0.001496         1024      1024.0   0.5750   0.6291       15
0.002153   0.000908         2048      2048.0   0.5204   0.4690       15
0.001347   0.000542         4096      4096.0   0.5042   0.4932       15
0.001101   0.000854         8192      8192.0   0.4967   0.5019       15
0.000951   0.000800        16384     16384.0   0.5011   0.4993       15
0.000952   0.000953        32768     32768.0   0.3915   0.3980       15
0.001235   0.001517        65536     65536.0   0.5043   0.5583       15

finished run
number of examples per pass = 74746
passes used = 1
weighted example sum = 69521
weighted label sum = 35113.3
average loss = 0.00124849
best constant = 0.505067
best constant's loss = 0.249974
total feature number = 1119986
