using l1 regularization = 0.01
final_regressor = models/mask.model
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = train-sets/0001.dat
num sources = 1
average    since         example     example  current  current  current
loss       last          counter      weight    label  predict features
1.000000   1.000000            1         1.0   1.0000   0.0000       51
0.507826   0.015651            2         2.0   0.0000   0.1251      104
0.260091   0.012356            4         4.0   0.0000   0.0582      135
0.243140   0.226188            8         8.0   0.0000   0.2116      146
0.253913   0.264686           16        16.0   1.0000   0.2895       24
0.240191   0.226469           32        32.0   0.0000   0.1874       32
0.241887   0.243583           64        64.0   0.0000   0.2205       61
0.246495   0.251103          128       128.0   1.0000   0.3094      106

finished run
number of examples per pass = 200
passes used = 1
weighted example sum = 200
weighted label sum = 91
average loss = 0.241252
best constant = 0.455
best constant's loss = 0.247975
total feature number = 15482
