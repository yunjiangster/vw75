final_regressor = models/0002c.model
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.45
using no cache
Reading datafile = train-sets/0002.dat
num sources = 1
average    since         example     example  current  current  current
loss       last          counter      weight    label  predict features
0.271591   0.271591            1         1.0   0.5211   0.0000       15
0.243842   0.216093            2         2.0   0.5353   0.0704       15
0.196605   0.149368            4         4.0   0.5854   0.2462       15
0.158729   0.120853            8         8.0   0.5575   0.2316       15
0.130670   0.102611           16        16.0   0.5878   0.2924       15
0.080250   0.029831           32        32.0   0.6038   0.5404       15
0.059089   0.037928           64        64.0   0.5683   0.3631       15
0.043301   0.027513          128       128.0   0.5351   0.3949       15
0.026872   0.010443          256       256.0   0.5385   0.5430       15
0.014994   0.003116          512       512.0   0.5053   0.5113       15
0.008170   0.001345         1024      1024.0   0.5750   0.5943       15
0.004479   0.000789         2048      2048.0   0.5204   0.4894       15
0.002404   0.000329         4096      4096.0   0.5042   0.4918       15
0.001491   0.000579         8192      8192.0   0.4967   0.5379       15
0.000968   0.000444        16384     16384.0   0.5011   0.5017       15
0.000761   0.000555        32768     32768.0   0.3915   0.4082       15
0.000871   0.000981        65536     65536.0   0.5043   0.4832       15

finished run
number of examples per pass = 74746
passes used = 1
weighted example sum = 69521
weighted label sum = 35113.3
average loss = 0.000872909
best constant = 0.505074
best constant's loss = 0.249974
total feature number = 1119986
