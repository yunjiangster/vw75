only testing
Num weight bits = 18
learning rate = 10
initial_t = 1
power_t = 0.5
predictions = 0002b.predict
using no cache
Reading datafile = train-sets/0002.dat
num sources = 1
average    since         example     example  current  current  current
loss       last          counter      weight    label  predict features
0.000495   0.000495            1         1.0   0.5211   0.5434       15
0.004557   0.008618            2         2.0   0.5353   0.4424       15
0.006604   0.008650            4         4.0   0.5854   0.4540       15
0.027281   0.047958            8         8.0   0.5575   0.4141       15
0.029507   0.031734           16        16.0   0.5878   0.4506       15
0.033135   0.036763           32        32.0   0.6038   0.4477       15
0.025336   0.017537           64        64.0   0.5683   0.6909       15
0.023115   0.020894          128       128.0   0.5351   0.6229       15
0.020109   0.017102          256       256.0   0.5385   0.4781       15
0.019899   0.019690          512       512.0   0.5053   0.3614       15
0.020524   0.021149         1024      1024.0   0.5750   0.4208       15
0.021089   0.021653         2048      2048.0   0.5204   0.5039       15
0.015512   0.009936         4096      4096.0   0.5042   0.4403       15
0.014047   0.012581         8192      8192.0   0.4967   0.5940       15
0.012359   0.010671        16384     16384.0   0.5011   0.4723       15
0.013142   0.013926        32768     32768.0   0.3915   0.5339       15
0.012558   0.011974        65536     65536.0   0.5043   0.4509       15

finished run
number of examples per pass = 74746
passes used = 1
weighted example sum = 69521
weighted label sum = 35113.3
average loss = 0.0119701
best constant = 0.505067
best constant's loss = 0.249974
total feature number = 1119986
